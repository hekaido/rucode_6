{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNegCHDBaahl+Ne/cBGwqh0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"gJkYtww6Pg8D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install madgrad"],"metadata":{"id":"EQ3Riizc17O9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","import os\n","import gc\n","import warnings\n","import random\n","from copy import deepcopy\n","import random\n","import math\n","\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.nn import Parameter\n","from torch.utils.data import Dataset, DataLoader\n","from madgrad import MADGRAD, MirrorMADGRAD\n","from torch.optim import AdamW\n","from transformers import (\n","    get_constant_schedule,\n","    get_constant_schedule_with_warmup,\n","    get_cosine_schedule_with_warmup,\n","    get_cosine_with_hard_restarts_schedule_with_warmup,\n","    get_linear_schedule_with_warmup,\n","    get_polynomial_decay_schedule_with_warmup\n",")\n","\n","from sklearn.model_selection import StratifiedKFold\n","    \n","from tqdm.notebook import tqdm\n","\n","warnings.filterwarnings(\"ignore\")\n","tqdm.pandas()"],"metadata":{"id":"lyTAfsc6PwYV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PROJECT_DIR = \"/content/drive/MyDrive/ml/Контесты/rucode_6/a\""],"metadata":{"id":"pSMMo28UPija"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# EDA"],"metadata":{"id":"Avpm7R4pykVC"}},{"cell_type":"code","source":["classes = ['Red', 'Green', 'Violet', 'White', 'Yellow', 'Brown', 'Black', 'Blue', 'Cyan', 'Grey', 'Orange']\n","counts = []\n","for class_name in classes:\n","    counts.append(len(os.listdir(f\"{PROJECT_DIR}/data/train/{class_name}\")))"],"metadata":{"id":"Db9Othg-yj3p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["help(sns.barplot)"],"metadata":{"id":"NKYJqqDcCeeM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.barplot(classes, counts, palette=classes)\n","# for i in range(len(classes)):\n","#     barplot[i].set_color(classes[i])"],"metadata":{"id":"jTZrYFuzzdwG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"BdUV3bfmymd6"}},{"cell_type":"code","source":["classes = ['Red', 'Green', 'Violet', 'White', 'Yellow', 'Brown', 'Black', 'Blue', 'Cyan', 'Grey', 'Orange']\n","target_encoder = {}\n","for i in range(len(classes)):\n","    target_encoder[classes[i]] = i"],"metadata":{"id":"_dDnYBq1xnpX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","from torchvision.io import read_image\n","\n","\n","class CarDataset(Dataset):\n","    def __init__(self, dir, transform=None, target_encoder: dict = None):\n","        self.transform = transform\n","        self.target_encoder = target_encoder\n","        class_names = os.listdir(dir)\n","        print(class_names)\n","        self.filenames = []\n","        self.labels = []\n","\n","        for class_name in tqdm(class_names):\n","            class_path = f\"{dir}/{class_name}\"\n","            images = os.listdir(class_path)\n","            for image in images:\n","                self.filenames.append(f\"{dir}/{class_name}/{image}\")\n","                self.labels.append(class_name)\n","\n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.filenames[idx]\n","        image = read_image(img_path)\n","        label = self.labels[idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","        \n","        if self.target_encoder:\n","            label = self.target_encoder[label]\n","\n","        return image, label"],"metadata":{"id":"MxG5PzaNQTLM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = CarDataset(f\"{PROJECT_DIR}/data/train\", target_encoder=target_encoder)"],"metadata":{"id":"phU8SYNivC1W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Losses"],"metadata":{"id":"9b-l0SNG0kl6"}},{"cell_type":"code","source":["class FocalLoss(nn.Module):\n","    def __init__(self, gamma=0, eps=1e-7):\n","        super(FocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.eps = eps\n","        self.ce = torch.nn.CrossEntropyLoss()\n","\n","    def forward(self, input, target):\n","        logp = self.ce(input, target)\n","        p = torch.exp(-logp)\n","        loss = (1 - p) ** self.gamma * logp\n","        return loss.mean()\n","\n","\n","class ArcFaceLoss(nn.Module):\n","    def __init__(self, s=45.0, m=0.1, crit=\"bce\", weight=None, reduction=\"mean\",\n","                 focal_loss_gamma=0, class_weights_norm=\"batch\"):\n","        super().__init__()\n","\n","        self.weight = weight\n","        self.reduction = reduction\n","        self.class_weights_norm = class_weights_norm\n","        \n","        if crit == \"focal\":\n","            self.crit = FocalLoss(gamma=focal_loss_gamma)\n","        elif crit == \"bce\":\n","            self.crit = nn.CrossEntropyLoss(reduction=\"none\")   \n","\n","        if s is None:\n","            self.s = torch.nn.Parameter(torch.tensor([45.], requires_grad=True, device='cuda'))\n","        else:\n","            self.s = s\n","\n","        self.cos_m = math.cos(m)\n","        self.sin_m = math.sin(m)\n","        self.th = math.cos(math.pi - m)\n","        self.mm = math.sin(math.pi - m) * m\n","        \n","    def forward(self, logits, labels):\n","\n","        logits = logits.float()\n","        cosine = logits\n","        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n","        phi = cosine * self.cos_m - sine * self.sin_m\n","        phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n","        \n","        labels2 = torch.zeros_like(cosine)\n","        labels2.scatter_(1, labels.view(-1, 1).long(), 1)\n","        labels2 *= (1 - 0.1)\n","        labels2 += 0.005\n","        output = (labels2 * phi) + ((1.0 - labels2) * cosine)\n","\n","        s = self.s\n","\n","        output = output * s\n","        loss = self.crit(output, labels)\n","\n","        if self.weight is not None:\n","            w = self.weight[labels].to(logits.device)\n","\n","            loss = loss * w\n","            if self.class_weights_norm == \"batch\":\n","                loss = loss.sum() / w.sum()\n","            if self.class_weights_norm == \"global\":\n","                loss = loss.mean()\n","            else:\n","                loss = loss.mean()\n","            \n","            return loss\n","        if self.reduction == \"mean\":\n","            loss = loss.mean()\n","        elif self.reduction == \"sum\":\n","            loss = loss.sum()\n","        return loss"],"metadata":{"id":"MrSjnBd20mSk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modules"],"metadata":{"id":"girCXnzE0m48"}},{"cell_type":"code","source":["class ArcMarginProduct(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super().__init__()\n","        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        nn.init.xavier_uniform_(self.weight)\n","\n","    def forward(self, features):\n","        cosine = F.linear(F.normalize(features), F.normalize(self.weight))\n","        return cosine"],"metadata":{"id":"A_8SSmFU0nfO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"0B3NCJxD1PeS"}},{"cell_type":"code","source":[],"metadata":{"id":"jOkK463m1Qbk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Loops"],"metadata":{"id":"G7DhepxS1dO_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"016aad72"},"outputs":[],"source":["def train_epoch(model, data_loader, loss_function, optimizer, scheduler, device):\n","    model.train()\n","    total_train_loss = 0\n","\n","    dl_size = len(data_loader)\n","\n","    batch_i = 0\n","\n","    for batch in tqdm(data_loader):\n","        b_input_ids = batch[0].to(device)\n","        b_attention_mask = batch[1].to(device)\n","        b_target = batch[2].to(device)\n","        \n","        optimizer.zero_grad()        \n","        logits = model(b_input_ids, b_attention_mask)\n","        b_probas = torch.softmax(logits, dim=1)\n","\n","        loss = loss_function(logits, b_target)\n","        total_train_loss += loss.item()\n","\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        scheduler.step()\n","    \n","    return total_train_loss / dl_size    \n","    \n","    \n","def eval_epoch(model, data_loader, loss_function, device):\n","    model.eval()\n","    total_train_loss = 0\n","\n","    dl_size = len(data_loader)\n","\n","    \n","    for batch in tqdm(data_loader):\n","        b_input_ids = batch[0].to(device)\n","        b_attention_mask = batch[1].to(device)\n","        b_target = batch[2].to(device)\n","        \n","        with torch.no_grad():\n","            logits = model(b_input_ids, b_attention_mask)\n","            b_probas = torch.softmax(logits, dim=1)\n","        \n","        loss = loss_function(logits, b_target)\n","        total_train_loss += loss.item()\n","    \n","    return total_train_loss / dl_size"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"602cd4af"},"outputs":[],"source":["def cross_validation(model, \n","                     dataset, \n","                     strat_array, \n","                     loss_function, \n","                     device=torch.device(\"cpu\"),\n","                     random_state: int=69, \n","                     n_folds: int=4, \n","                     epochs: int=5, \n","                     lr: float=1e-6,\n","                     start_fold: int=0, \n","                     batch_size: int=32):\n","    random.seed(random_state),\n","    np.random.seed(random_state)\n","    torch.manual_seed(random_state)\n","    torch.cuda.manual_seed_all(random_state)\n","    \n","    loss_function.to(device)\n","\n","    kfold = StratifiedKFold(4, shuffle=True, random_state=69)\n","    for fold, (train_ids, eval_ids) in enumerate(kfold.split(dataset, strat_array)):\n","        if fold >= start_fold:\n","            print(f'FOLD {fold}')\n","            print('--------------------------------')\n","\n","            fold_model = deepcopy(model)\n","            fold_model.to(device)\n","\n","            optimizer = MADGRAD(\n","                model.parameters(),\n","                lr = lr, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","            )\n","            \n","            train_subsampler = torch.utils.data.Subset(dataset,  train_ids)\n","            train_loader = torch.utils.data.DataLoader(\n","                          train_subsampler, \n","                          batch_size=batch_size)\n","\n","            eval_subsampler = torch.utils.data.Subset(dataset,  eval_ids)\n","            eval_loader = torch.utils.data.DataLoader(\n","                          eval_subsampler,\n","                          batch_size=batch_size)\n","            \n","            total_steps = len(train_loader) * epochs \n","\n","            scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                                    num_warmup_steps = 0, # Default value in run_glue.py\n","                                                    num_training_steps = total_steps)\n","\n","            mrrs = []\n","\n","            for epoch_i in range(0, epochs):\n","                train_epoch(fold_model, train_loader, loss_function, optimizer, scheduler, device)\n","                eval_epoch(fold_model, eval_loader, loss_function, device)\n","\n","\n","def single_model(model, \n","                     dataset, \n","                     loss_function, \n","                     device=torch.device(\"cuda\"),\n","                     random_state: int=69, \n","                     epochs: int=5, \n","                     lr: float=1e-6,\n","                     batch_size: int=32,\n","                     ):\n","    random.seed(random_state),\n","    np.random.seed(random_state)\n","    torch.manual_seed(random_state)\n","    torch.cuda.manual_seed_all(random_state)\n","    \n","    loss_function.to(device)\n","    model.to(device)\n","\n","    optimizer = MADGRAD(\n","        model.parameters(),\n","        lr = lr, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","    )\n","\n","    data_loader = torch.utils.data.DataLoader(\n","                    dataset,\n","                    batch_size=batch_size)\n","    \n","    total_steps = len(data_loader) * epochs \n","\n","    scheduler = get_cosine_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)\n","\n","    losses = []\n","\n","    for epoch_i in range(0, epochs):\n","        if epoch_i >= start_epoch:\n","            epoch_path = f\"{path}/epoch_{epoch_i}/\"\n","            os.mkdir(epoch_path)\n","\n","            epoch_loss = train_epoch(model, data_loader, loss_function, optimizer, scheduler, device)\n","            losses.append(epoch_loss)\n","            print(\"EPOCH\", epoch_i, epoch_loss)\n","            \n","            # eval_epoch(fold_model, eval_loader, loss_function, device)"]},{"cell_type":"markdown","source":["# Cross Validation"],"metadata":{"id":"pOY06p6r2Ur9"}},{"cell_type":"code","source":["model = Model()\n","for p in model.parameters():\n","    if p.dim() > 1:\n","        nn.init.xavier_uniform_(p)"],"metadata":{"id":"5z7MLDul2V7J"},"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Imports"],"metadata":{"id":"G4Wwdz0zK6zL"}},{"cell_type":"code","source":["pip install torchmetrics"],"metadata":{"id":"uRCj5FJw6nWt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"gJkYtww6Pg8D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","import os\n","import gc\n","import warnings\n","import random\n","from copy import deepcopy\n","import random\n","import math\n","\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import torchvision\n","\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.nn import Parameter\n","from torchmetrics import Accuracy\n","from torch.utils.data import Dataset, DataLoader\n","from skimage.transform import resize\n","from torch.optim import AdamW\n","\n","from sklearn.model_selection import StratifiedKFold\n","    \n","from tqdm.notebook import tqdm\n","\n","warnings.filterwarnings(\"ignore\")\n","tqdm.pandas()"],"metadata":{"id":"lyTAfsc6PwYV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PROJECT_DIR = \"/content/drive/MyDrive/a\""],"metadata":{"id":"pSMMo28UPija"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")"],"metadata":{"id":"H5rrcEHDAcbR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# EDA"],"metadata":{"id":"Avpm7R4pykVC"}},{"cell_type":"code","source":["classes = ['Red', 'Green', 'Violet', 'White', 'Yellow', 'Brown', 'Black', 'Blue', 'Cyan', 'Grey', 'Orange']\n","classes_sns = ['Red', 'Green', 'Violet', 'Pink', 'Yellow', 'Brown', 'Black', 'Blue', 'Cyan', 'Grey', 'Orange']\n","counts = []\n","for class_name in classes:\n","    counts.append(len(os.listdir(f\"{PROJECT_DIR}/data/train/{class_name}\")))"],"metadata":{"id":"Db9Othg-yj3p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.barplot(classes, counts, palette=classes_sns)"],"metadata":{"id":"jTZrYFuzzdwG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"BdUV3bfmymd6"}},{"cell_type":"code","source":["classes = ['Red', 'Green', 'Violet', 'White', 'Yellow', 'Brown', 'Black', 'Blue', 'Cyan', 'Grey', 'Orange']\n","target_encoder = {}\n","for i in range(len(classes)):\n","    target_encoder[classes[i]] = i"],"metadata":{"id":"_dDnYBq1xnpX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","from torchvision.io import read_image\n","\n","\n","class CarDataset(Dataset):\n","    def __init__(self, dir, transform=None, target_encoder: dict = None):\n","        self.transform = transform\n","        self.target_encoder = target_encoder\n","        class_names = os.listdir(dir)\n","        print(class_names)\n","        self.filenames = []\n","        self.labels = []\n","\n","        for class_name in tqdm(class_names):\n","            class_path = f\"{dir}/{class_name}\"\n","            images = os.listdir(class_path)\n","            for image in images:\n","                self.filenames.append(f\"{dir}/{class_name}/{image}\")\n","                self.labels.append(class_name)\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.filenames[idx]\n","        image = read_image(img_path)\n","        label = self.labels[idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","        \n","        if self.target_encoder:\n","            label = self.target_encoder[label]\n","\n","        return image, label"],"metadata":{"id":"MxG5PzaNQTLM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = CarDataset(f\"{PROJECT_DIR}/data/train\", target_encoder=target_encoder)"],"metadata":{"id":"phU8SYNivC1W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(dataset)"],"metadata":{"id":"DOqQfKbKCqKK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean = [0.485, 0.456, 0.406]\n","std = [0.229, 0.224, 0.225]\n","\n","transforms=torchvision.transforms.Compose([\n","    torchvision.transforms.Resize(size=(256,256)),\n","    torchvision.transforms.ToTensor(),\n","    torchvision.transforms.Lambda(lambda a: a / 255),\n","    torchvision.transforms.Normalize(mean, std)\n","])"],"metadata":{"id":"gOFxdRFa0pY4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ids = [i for i in range(0, 1000)]\n","eval_ids = [i for i in range(1000, 1300)]"],"metadata":{"id":"E2t9eDbXGbmM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_path = '/content/drive/MyDrive/a/data'\n","train_folder = torchvision.datasets.ImageFolder(data_path + '/train', transform=transforms)"],"metadata":{"id":"z04lSvx135BW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_subsampler = torch.utils.data.Subset(train_folder,  train_ids)\n","train_loader = torch.utils.data.DataLoader(train_subsampler, batch_size=64, num_workers=1, shuffle=True)\n","eval_subsampler = torch.utils.data.Subset(train_folder,  eval_ids)\n","eval_loader = torch.utils.data.DataLoader(eval_subsampler, batch_size=64, num_workers=1, shuffle=False)"],"metadata":{"id":"yEtsz_f9GORt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Losses"],"metadata":{"id":"9b-l0SNG0kl6"}},{"cell_type":"code","source":["class FocalLoss(nn.Module):\n","    def __init__(self, gamma=0, eps=1e-7):\n","        super(FocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.eps = eps  \n","        self.ce = torch.nn.CrossEntropyLoss()\n","\n","    def forward(self, input, target):\n","        logp = self.ce(input, target)\n","        p = torch.exp(-logp)\n","        loss = (1 - p) ** self.gamma * logp\n","        return loss.mean()"],"metadata":{"id":"MrSjnBd20mSk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Loops"],"metadata":{"id":"G7DhepxS1dO_"}},{"cell_type":"code","source":["accuracy = Accuracy(num_classes=11)"],"metadata":{"id":"KT9K2u6H65Qv"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"016aad72"},"outputs":[],"source":["def train_epoch(model, data_loader, loss_function, optimizer, scheduler, device):\n","\n","    model.train(True)\n","    model.to(device)\n","    total = len(data_loader.dataset)  \n","    epoch_loss, epoch_acc = 0, 0\n","\n","    for input, target in data_loader:\n","        input, target = input.to(device), target.to(device) #prepare for train\n","        optimizer.zero_grad()\n","        preds = model(input) #model predicts\n","\n","        loss = loss_function(preds, target)\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_acc += accuracy(preds, target) #accuaracy\n","\n","    epoch_acc = epoch_acc / total\n","    epoch_loss = epoch_loss / total\n","    \n","    return epoch_loss, epoch_acc\n","    \n","    \n","def eval_epoch(model, data_loader, loss_function, device):\n","    model.train(False)\n","    model.to(device)\n","    epoch_loss = 0\n","    epoch_acc = 0\n","    total = len(data_loader)\n","\n","    for input, target in data_loader:\n","        input, target = input.to(device), target.to(device)\n","        with torch.no_grad():\n","            preds = model(input)\n","            loss = loss_function(preds, target)\n","            epoch_loss += loss.item()\n","            epoch_acc += accuracy(preds, target)\n","\n","    epoch_acc = epoch_acc / total\n","    epoch_loss = epoch_loss / total\n","\n","    return epoch_loss, epoch_acc"]},{"cell_type":"markdown","source":["#Model and train"],"metadata":{"id":"ksCw6D09Aw0E"}},{"cell_type":"code","source":["model = torchvision.models.resnet18(weights = \"ResNet18_Weights.IMAGENET1K_V1\")\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr = 0.001)\n","scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n","loss = FocalLoss()"],"metadata":{"id":"qXnz0gn3A1y4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for name, param in model.named_parameters():\n","  if not name.startswith(\"layer4.1\"):\n","    param.requires_grad = False\n","for name, par in model.named_parameters():\n","  if par.requires_grad:\n","       print(name)"],"metadata":{"id":"EdXIliQcBNkR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fc = torch.nn.Linear(512, 11, bias = True)"],"metadata":{"id":"sVvWqK0lBQrJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 5\n","for i in tqdm(range(epochs)):\n","    train_loss, train_accuracy = train_epoch(model, train_loader, loss, optimizer, scheduler, device)\n","    test_loss, test_accuracy = eval_epoch(model, eval_loader, loss,  device)\n","    print(f'\\n Epoch #{i + 1}\\nTrain loss = {train_loss}, Train accuracy = {train_accuracy}')\n","    print(f'Test loss = {test_loss}, Test accuracy = {test_accuracy}')"],"metadata":{"id":"4aBY9CtkAXJd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Cross Validation"],"metadata":{"id":"pOY06p6r2Ur9"}}]}